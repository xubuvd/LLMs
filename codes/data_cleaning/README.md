```
Author: xubuvd
Date: 13/08/2024
Email: xubuvd@163.com
```

# ğŸŒ± æ•°æ®æ¸…æ´—æ–¹æ¡ˆ - Data Cleaning Recipe
å®ƒåŒ…å«å››ä¸ªä¸»è¦é˜¶æ®µï¼š<br>
1. **åˆå§‹æ•°æ®æ¸…æ´—**ï¼šå¯¹28ä¸ªç‰¹å®šé¢†åŸŸçš„æ•°æ®é›†åº”ç”¨å¤šç§å¯å‘å¼è¿‡æ»¤æ–¹æ³•ã€‚<br>
2. **æ–‡æ¡£çº§å»é‡**ï¼šä½¿ç”¨ MiniHash å»é™¤é‡å¤æ–‡æ¡£ã€‚<br>
3. **ç»Ÿè®¡åˆ†æ**ï¼šä½¿ç”¨ Llama3.1-8b-Instruct æ¨¡å‹åˆ†ææ€»è¯æ±‡é‡ã€‚<br>
4. **äººå·¥è¯„ä¼°**ï¼šå¯¹100ä¸ªæ•°æ®ç‚¹è¿›è¡ŒæŠ½æ ·å’Œæ‰‹åŠ¨å®¡æŸ¥ã€‚<br>
<br>
It consists of four main stages:<br>
1. **Initial Data Cleaning**: Apply various heuristic filtering methods to 28 domain-specific datasets.<br>
2. **Document-Level Deduplication**: Use MiniHash to remove duplicate documents.<br>
3. **Statistical Analysis**: Analyze the total number of tokens using the Llama3.1-8b-Instruct model.<br>
4. **Human Evaluation**: Conduct a manual review by sampling 100 data points.<br>

# ğŸ‚ å¯åŠ¨å’Œæš‚åœ - running and killing
```
nohup bash run_data_cleaning.sh > r.log 2>&1 &
bash stopall.sh
```

