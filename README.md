# ä¸­æ–‡é¢†åŸŸå¤§è¯­è¨€æ¨¡å‹å®æ“æŠ€æœ¯å…¨æ ˆ

## Scaling law for SFT & DPO
coming soon...

## é¢„è®­ç»ƒã€SFTå’ŒDPOåå¥½å¯¹é½ä»£ç æ¡†æ¶
å·²ç»åœ¨36å°A100ï¼Œ288å—GPUå¡ä¸Šå®é™…è·‘è¿‡é¢„è®­ç»ƒã€å¢é‡é¢„è®­ç»ƒå’ŒSFTï¼Œæ¶‰åŠ1.5Tçš„tokensè®­ç»ƒï¼Œç­‰å¾…å¼€æº...<br>

### SFTä»£ç å¼€æº
åœ°å€ï¼šhttps://github.com/xubuvd/PhasedSFT<br>
ä»£ç åœ¨16å°A100ã€A800å’ŒH100æœºå™¨ä¸Šï¼Œç»å—è¿‡äº†å¤§è§„æ¨¡çš„SFTè®­ç»ƒï¼Œæ•°æ®é‡æœ€å¤šè¾¾ 200ä¸‡æ¡ï¼Œå·²ç»è®­ç»ƒè¿‡çš„æ¨¡å‹æœ‰Llama1ã€Llama2ã€Llama3ã€Qwen1ã€Qwen1.5ã€Qwen2 å’Œ Mistralï¼Œç¨³å®šå¯ç”¨çš„ã€‚<br>

### åå¥½è®­ç»ƒ Post-Training with Direct Preference Optimization
```
åœ°å€ï¼šcodes_datasets/Postraining_dpo
ç”¨æ³•å‚è€ƒï¼šcodes_datasets/Postraining_dpo/README.md
```
ä»£ç åœ¨16å°A100ã€A800å’ŒH100æœºå™¨ä¸Šè®­ç»ƒè¿‡ï¼ŒDPOåå¥½æ•°æ®æœ€å¤šåˆ°50ä¸‡æ¡ï¼Œç¨³å®šå¯ç”¨ã€‚

## é¢„è®­ç»ƒæ•°æ®æ¸…æ´—æºä»£ç å’Œé«˜å¹¶å‘æ¡†æ¶
å¤§è§„æ¨¡é¢„è®­ç»ƒæ•°æ®é›†æ•°æ®é›†æ¸…æ´—ï¼Œå…·æœ‰å¯è¯»æ€§å¥½ã€å¯ç”¨æ€§å¥½ï¼ŒPythonå¤šçº¿ç¨‹å¹¶å‘ï¼ŒåŒ…æ‹¬ä¸€å¥—æ¸…æ´—å·¥ç¨‹è§„èŒƒï¼Œæ¸…æ´—ç­–ç•¥ï¼Œå¤šçº¿ç¨‹æ¡†æ¶ï¼Œæ–‡æœ¬å»é‡ä»£ç ï¼Œé»‘åå•è¯å…¸ç­‰å†…å®¹ã€‚<br>
2024.08.13ï¼Œå¼€æºå‡ºæ¥ä¸€éƒ¨åˆ†åŸºäºå¯å‘å¼è§„åˆ™çš„å¤šçº¿ç¨‹pythonæ¸…æ´—ä»£ç ï¼Œä»£ç å¤ç”¨æ€§ã€å¯ç”¨æ€§å¥½ï¼šcodes_datasets/DataCleaning<br>
æ¸…æ´—ä»£ç å”¯ä¸€çš„å¯åŠ¨è„šæœ¬ï¼š<br>
```
nohup bash run_data_cleaning.sh > r.log 2>&1 &
```
åœæ­¢ç¨‹åºçš„è„šæœ¬ï¼š<br>
```
bash stopall.sh
```
## SFT æ•°æ®é›†æ¸…æ´—å’Œæ•°æ®è´¨é‡æå‡ä»£ç æ¡†æ¶
ğŸ‚step1: æ•°æ®æ¸…æ´—ï¼Œä¹Ÿå¯å¤ç”¨é¢„è®­ç»ƒæ•°æ®æ¸…æ´—ä»£ç <br>
ğŸ‚step2: æ•°æ®è´¨é‡æå‡<br>
1.æŒ‡ä»¤è´¨é‡æ‰“åˆ†<br>
2.æŒ‡ä»¤éš¾åº¦æ‰“åˆ†<br>
3.èšç±»+è¯­ä¹‰å»é‡å¤<br>
ä»£ç æ•´ç†ä¸­ï¼Œç­‰å¾…å¼€æº...<br>

## ä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹çš„å®‰å…¨å¯¹é½å·¥ä½œï¼Œç”¨äºå®‰å…¨å®¡æ ¸è¯„ä¼°
ä¸€åƒæ¡å®‰å…¨ç±»æŒ‡ä»¤æ•°æ®é›†:codes_datasets/SFTData/cn-Safety-Prompts-gpt12k_baichuan1K.jsonl<br>
ä¸€åƒæ¡å®‰å…¨ç±»ä¸­æ–‡æŒ‡ä»¤æ•°æ®é›†,å…³äºè¯ˆéª—ã€æ¬ºéª—ã€ä¸ªäººå®‰å…¨ã€ä¸ªäººæ”»å‡»æ€§æ­§è§†æ€§ä»‡æ¨è¨€è®ºã€é»„èµŒæ¯’ç­‰ç±»å‹: codes_datasets/SFTData/cn-Chinese-harmlessness-1K.jsonl<br>

## å¼€æºsftæ•°æ®é›†æ„é€ 
### 1. å¤§è§„æ¨¡COTé«˜ä¸­è¯•é¢˜æ•°æ®é›†ï¼Œå‘½åä¸ºâ€œcn-sft-exams-highSchool-1M.jsonlâ€
å¼€æºè¶…å¤§è§„æ¨¡é«˜ä¸­è¯•é¢˜æŒ‡ä»¤æ•°æ®é›†ï¼Œ100ä¸‡æ¡ä¸­æ–‡æŒ‡ä»¤æ•°æ®ï¼Œæ¶µç›–è¯­æ–‡ã€æ•°å­¦ã€ç‰©ç†ã€åŒ–å­¦ã€åœ°ç†ã€å†å²ã€æ”¿æ²»å’Œè‹±æ–‡ã€‚<br>
å·²ä¸Šä¼ ï¼šcn-sft-exams-highSchool-1k.jsonl<br>
æŒ‡ä»¤æ ¼å¼ï¼š{"id": "26069", "data": ["é—®é¢˜","ç­”æ¡ˆ"]}<br>

### 2. SFTæ•°æ®è´¨é‡ä¼˜åŒ–
æ•°æ®è´¨é‡å’Œå¤šæ ·æ€§ï¼Œè¿™ä¸¤æ¡æ˜¯æ¨¡å‹èƒ½åŠ›çš„æ¥æºã€‚<br>
ä¼˜åŒ–å‰ï¼š<br>
![sftExp8 2_tsne_100000](https://github.com/user-attachments/assets/5f38e112-ed85-47fa-b919-e8431fc63af6)
<br>
ä¼˜åŒ–åï¼š<br>
![sftExp8 3_tsne_100000](https://github.com/user-attachments/assets/5a0fe60a-a8ea-48a5-ba04-7945ea7995a7)
ä¸Šè¿°æ•°æ®åˆ†å¸ƒå›¾ç”Ÿæˆä»£ç ï¼šcodes_datasets/utils/tsne_cluster_show.py<br>

### 2. è¡Œæ”¿èŒä¸šèƒ½åŠ›æµ‹éªŒé¢˜æ•°æ®é›†ï¼Œå‘½åä¸ºâ€œcn-sft-CS-APAT-30K.jsonlâ€
å…± 3 ä¸‡æ¡è¡Œæµ‹è¯•é¢˜ï¼Œé€»è¾‘æ¨ç†é¢˜ç›®ï¼Œæ—¨åœ¨æå‡æ¨¡å‹çš„é€»è¾‘èƒ½åŠ›ã€‚<br>
å·²ä¸Šä¼ ï¼šcn-exam-high-school-5W.jsonl.zip<br>
æŒ‡ä»¤æ ¼å¼ï¼š{"id": "26069", "data": ["é—®é¢˜","ç­”æ¡ˆ"]}<br>

## è½åœ°å¤§è¯­è¨€æ¨¡å‹LLMï¼Œå…³é”®é—®é¢˜æ˜¯åœ¨æŸä¸ªå‚ç›´é¢†åŸŸï¼Œå¦‚ä½•æ„é€ é«˜è´¨é‡æŒ‡ä»¤æ•°æ®é›†ï¼Ÿæœ‰æ–¹æ³•è®ºå—ï¼Ÿ
æœ‰çš„ï¼<br>

## ä»0åˆ°1é¢„è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹
é¢„è®­ç»ƒæ¡†æ¶ï¼šåŸºäº DeepSpeed + HuggFace Trainer ç ”å‘æ¡†æ¶<br>
æ¨¡å‹ç»“æ„ï¼š LLaMAï¼›<br>

## è®ºæ–‡å¼•ç”¨è¯·å‚è€ƒ
```
@online{CnSftData,
  author = {XuBu},
  year = {2024},
  title = {Chinese Large Language Models},
  url = {https://github.com/xubuvd/LLMs},
  month = {APR},
  lastaccessed = {APR 19, 2024}
}
```

## sftå¾®è°ƒè®­ç»ƒå’Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒ
SFTï¼šä½¿ç”¨ä¸Šä¸€æ­¥çš„é¢„è®­ç»ƒæ¡†æ¶ (å¼ƒç”¨DeepSpeedChatï¼Œå› ä¸ºå®ƒä¸æ”¯æŒå¤§è§„æ¨¡æ•°æ®è®­ç»ƒï¼Œå­˜åœ¨å¾ˆå¤šé—®é¢˜)<br>
RLHFæ¡†æ¶ï¼šä½¿ç”¨ä¼˜åŒ–è¿‡çš„ DeepSpeedChat è¿›è¡Œè®­ç»ƒ<br>

## DPO åå¥½æ•°æ®å¯¹é½
DPOéå¸¸æœ‰æ•ˆï¼Œç›®å‰åœ¨3ä¸‡åå¥½æ•°æ®é›†ä¸Šï¼Œæµ‹è¯•13Bã€70Bå’Œ7Bæ¨¡å‹ï¼Œæ•ˆæœéå¸¸æ˜¾è‘—ï¼›<br>
DPOç‰ˆæœ¬ç›¸å¯¹äºSFTæ¨¡å‹ï¼Œèƒœç‡æå‡äº† ã€Œ10ä¸ªã€ç™¾åˆ†ç‚¹ä»¥ä¸Šï¼Œäººçš„è§‚æ„Ÿæ”¶ç›Šä¹Ÿå¾ˆæ˜¾è‘—ã€‚å…·ä½“çš„ï¼Œåœ¨ä¸šåŠ¡ä¸Šçš„å‡†ç¡®ç‡ï¼ˆaccuracyï¼‰ï¼Œç›¸å¯¹äºSFTæ¨¡å‹ï¼Œæå‡äº† ã€Œ14.6ã€ä¸ªç™¾åˆ†ç‚¹ï¼ŒF1å€¼ï¼Œæå‡äº† ã€Œ13.5ã€ä¸ªç™¾åˆ†ç‚¹ã€‚<br>
### DPOååºæ•°æ®é›†æ„é€ <br>
### DPOè®­ç»ƒï¼Œå…³é”®æŒ‡æ ‡å›¾ç¤º(ä¸€éƒ¨åˆ†)ï¼š<br>
![Screen Shot 2023-12-14 at 2 24 54 PM](https://github.com/xubuvd/LLMs/assets/59753505/f22b0b2d-02ba-4cf5-aae2-77085664779c)

## é¢„è®­ç»ƒæ•°æ®æ”¶é›†å’Œæ¸…æ´—
æ•°æ®æ”¶é›†å’Œæ¸…æ´—ï¼Œå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æœ€ç»ˆæ•ˆæœçš„å½±å“æåº¦é‡è¦ã€‚<br>
æ•°æ®æ¸…æ´—éœ€è¦ä¸€å¥—æ–¹æ³•è®ºï¼Œé¢„è®­ç»ƒæ•°æ®çš„ä¸‰é¡¹å…³é”®æŒ‡æ ‡ï¼šè´¨é‡é«˜ã€å¤šæ ·æ€§å’Œæ•°é‡å¤§ã€‚<br>
### ä»€ä¹ˆæ˜¯è´¨é‡é«˜ï¼Ÿ
- ä¸€å¤§æ®µè‡ªç„¶è¯­è¨€æ–‡æœ¬ï¼Œè¯­æ³•ä¸Šè¿è´¯æµç•…ï¼Œæ²¡æœ‰æ’å…¥æ— å…³çš„è¯æ±‡ã€å¥å­ï¼Œè¯­ä¹‰ä¸Šå®Œæ•´ï¼›<br>
- æ ‡ç‚¹ç¬¦å·ç¬¦åˆè¡Œæ–‡è§„èŒƒï¼›
### ä»€ä¹ˆæ˜¯å¤šæ ·æ€§ï¼Ÿ
  - è¦†ç›–å„ä¸ªé€šç”¨é¢†åŸŸå’Œå­¦ç§‘çš„çŸ¥è¯†<br>
  - æ„å»ºä¸€ä¸ªå…¨é¢çš„ã€Œè¡Œä¸šé¢†åŸŸçŸ¥è¯†ä½“ç³»ã€<br>
  - æ•´åˆä¸Šè¿°å„ç±»ä¿¡æ¯æºï¼Œç¡®ä¿å¹¿æ³›çš„çŸ¥è¯†è¦†ç›–<br>
### ä»€ä¹ˆæ˜¯æ•°é‡å¤§ï¼Ÿ
- æ€»é‡<br>
  - Pretrain æ•°æ®æ€»é‡å¤§ï¼Œä»¥LLaMA tokensè®¡ç®—ï¼Œçº¦ 1~2 T tokens å·¦å³<br>
- åˆ†é‡<br>
  - ä»æ•°æ®å¤šæ ·æ€§ä¸Šçœ‹ï¼Œå„ç§æ•°æ®ç±»å‹çš„æ•°æ®éƒ½æœ‰ï¼Œå¤§å°åŸºæœ¬ç¬¦åˆäº’è”ç½‘ä¸Šçš„æ•°æ®è‡ªç„¶åˆ†å¸ƒ<br>

## äº¤æµç¾¤
å¦‚æœä½ ä¹Ÿå¯¹æœ¬é¡¹ç›®æ„Ÿå…´è¶£ï¼Œæ¬¢è¿åŠ å…¥ç¾¤èŠå‚ä¸è®¨è®ºäº¤æµã€‚
![xubu](https://github.com/xubuvd/LLMs/assets/59753505/1841da9f-110e-4b91-be0a-dbe351b399a0)

## åŸºäºDeepSpeedChatæ”¹é€ ï¼Œç”¨äºRLHFè®­ç»ƒçš„æ¡†æ¶
No.      |Bug             |     åŸåšæ³•    | ä¿®æ”¹           | æ³¨è¯„
 --------| :-----------:  |:-----------:  | :-----------:|:-----------:|
 1       | Lossè®¡ç®—æ–¹å¼ | æ‰€æœ‰tokensçš„é¢„æµ‹æŸå¤±ï¼ˆCE lossï¼‰ |åªè®¡ç®—æ¨¡å‹respnseéƒ¨åˆ†çš„é¢„æµ‹æŸå¤± | è®¡ç®—æ‰€æœ‰tokençš„lossï¼Œæ•ˆæœä¸å¥½ï¼Œåªè®¡ç®—æ¨¡å‹responseçš„lossï¼Œå…¶å®ƒéƒ¨åˆ†maskæ‰
 2       | æ–°å¢pre-trainå’Œ<br>SFTä¸¤ç§æŸå¤±Lossè®¡ç®—  |  åªæœ‰lossè®¡ç®—ä¸€ç§ |å¢åŠ pre-trainé¢„è®­ç»ƒ | æ”¯æŒSFTå’ŒPre-trainæ··åˆè®­ç»ƒï¼ŒåŒä¸€ä¸ªbatchå†…éƒ¨æœ‰ä¸¤ç±»æ•°æ®
 3       | <endoftext>ä¸ä½œä¸ºä¸€ä¸ªç‰¹æ®Šå­—ç¬¦ | <endoftext>ä½œä¸ºä¸€ä¸ªæ–‡æœ¬åºåˆ— | ä½¿ç”¨<eos>ç‰¹æ®Šå­—ç¬¦ä»£æ›¿ï¼Œä¸éœ€è¦æ–°åŠ ä¸€ä¸ª<endoftext> | å‚è€ƒè®ºæ–‡â€œA General Language Assistant as a Laboratory for Alignmentâ€ï¼Œç”¨ä½œç‰¹æ®Šå­—ç¬¦æ•ˆæœå¥½ä¸€äº›ã€‚
 4  | subprocess.CalledProcessError: Command '['which', 'c++']' returned non-zero exit status 1. | g++ wasn't installed. | #apt-get install build-essential | g++ç¯å¢ƒé—®é¢˜
 5  | wandb.errors.UsageError: api_key not configured (no-tty). | |  #wandb login æ ¹æ®æç¤ºè·å–api keyæ³¨å†Œä¸€ä¸‹å³å¯ | wandbä½¿ç”¨é—®é¢˜ï¼Œé€€å‡ºåå†è¿›å…¥è¦ï¼š$ wandb login --relogin
 6 | Calling torch.distributed.barrier() <br>results in the program being killed |#df -lh | #rm -f /dev/shm/nccl-*|Dockerå®¹å™¨å…±äº«å†…å­˜å¤ªå°å­˜æ»¡å¯¼è‡´ï¼Œ<br>å®¹å™¨é‡Œè·‘è®­ç»ƒä¼šé‡åˆ°ï¼Œ<br>Slurmé›†ç¾¤é‡Œï¼Œé¢å¯¹è£¸æœºæ²¡æœ‰æ­¤ç±»é—®é¢˜ã€‚
 7 |huggingface/tokenizers: The current process just got forked, after parallelism has already been used. | | | warningï¼Œæš‚ä¸å¤„ç†
 8 | æ•°æ®é›†ç´¢å¼•å¤§å°çš„bug| | | 2982929829ä¸€ä¸ªä¸å¯èƒ½å‡ºç°çš„æ•°å­—ï¼Œ<br>indexç¼“å­˜æ–‡ä»¶åå­—åå­—é‡å¤ï¼ŒåŠ å…¥å­è¿›ç¨‹çš„<br>global rank, loacl rankå‘½åï¼Œå·²è§£å†³ã€‚
 9 |wandb: ERROR Run initialization has timed out after 60.0 sec. | |ä¸¤ä¸ªå¯èƒ½åŸå› ï¼š<br>1ï¼ŒæŸäº›nodeçš„ç½‘ç»œæ²¡æœ‰æ‰“å¼€å¯¼è‡´çš„ï¼›<br>2ï¼ŒèŠ‚ç‚¹çš„ç½‘ç»œä¸­æ–­ï¼›<br>ä¸Šè¿°ä¸¤ä¸ªåŸå› éƒ½é‡åˆ°è¿‡ã€‚ | æ’æŸ¥ä¸¤ä¸ªåŸå› 
 10 | OSError: [Errno 122] Disk quota exceeded| æ¨¡å‹æ–‡ä»¶checkpointå†™åˆ°ç®¡ç†èŠ‚ç‚¹æœ¬åœ°ï¼Œ<br>ä»…ä¿å­˜äº†4ä¸ªcheckpointsï¼Œç©ºé—´å°±ğŸˆµï¸äº†ï¼Œ<br>pytorch_model_10.bin,<br>pytorch_model_20.bin,<br>pytorch_model_30.bin,<br>pytorch_model_40.bin| 1. checkpointså…ˆä¿å­˜åœ¨/hpc_data/pangwei/ ã€å› ä¸ºå†™æƒé™é—®é¢˜ï¼Œå…ˆä¿å­˜è¯¥ç›®å½•ä¸‹ã€‘ï¼Œé€Ÿåº¦å˜æ…¢ï¼Œ10åˆ†é’ŸåŠ è½½æ¨¡å‹æ–‡ä»¶ï¼›<br>2. ä¿ç•™å½“å‰ä¸‰ä¸ªcheckpointsï¼›<br>3. ä¿å­˜å†å²ä¸Šæœ€å¥½çš„ä¸€ä¸ªcheckpointï¼Œæ ¹æ®éªŒè¯é›†ä¸Šçš„perplexityæŒ‡æ ‡ã€‚checkpointsåˆ†ä¸ºä¸‰ç§ï¼Œåç¼€åˆ†åˆ«ä¸ºï¼šnorm_{steps}, bestppl_{steps}, final_{steps}ã€‚| ç£ç›˜é…é¢ä¸å¤Ÿäº†ï¼Œç£ç›˜å·²æ»¡æˆ–è¶…å‡ºäº†ç”¨æˆ·æ‰€èƒ½ä½¿ç”¨çš„é…é¢ä¸Šé™
 11 |æ··åˆè®­ï¼Œæ”¯æŒä»»æ„å¤šä¸ªè®­ç»ƒæ•°æ®æ–‡ä»¶ | æ”¯æŒä¸€ç±»æ•°æ®é›†è¯»å–| æ”¯æŒå››ç±»ä¸åŒæ•°æ®é›†ï¼Œæ¯ä¸€ç±»å¯ä»¥ä»»æ„å¤šï¼š<br>--train_pt_data_path []<br>--eval_pt_data_path []<br>--train_sft_data_path []<br>--eval_sft_data_path []<br>é¢„è®­ç»ƒæ•°æ®é›†ï¼Œåç¼€ï¼šè®­ç»ƒé›†pt_train.jsonl, éªŒè¯é›† pt_eval.jsonl;<br>æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼Œåç¼€ï¼šè®­ç»ƒé›† sft_train.jsonl, éªŒè¯é›† sft_eval.jsonlã€‚ | æ”¯æŒæ··åˆè®­çš„æ•°æ®é›†ç®¡ç†ï¼Œä¾¿äºä¸åŒæ•°æ®é›†çš„é…æ¯”
 12 | resumeé—®é¢˜| | 1ï¼‰ä¿å­˜ checkpoint å…ƒä¿¡æ¯ï¼ŒåŒ…æ‹¬<br>epoch, global step, optimizer,<br>checkpoints file nameï¼›<br>2ï¼‰resume ç»§ç»­è®­ç»ƒï¼Œæ–­ç‚¹é‡æ–°è®­ç»ƒã€‚| åŠ è½½å½“å‰æœ€æ–°çš„ä¸€ä¸ªcheckpointï¼›
 13 | (ReqNodeNotAvail, Un)<br>scancelä¸€ä¸ªä»»åŠ¡<br>åˆé‡æ–°å¯åŠ¨ä¼š<br>é‡åˆ°æ­¤ç±»é”™è¯¯| | slurmç³»ç»Ÿscancelä»»åŠ¡åæŒ‚æ‰| é‡å¯slurmå§
 14 | ç¼“å­˜ç©ºé—´æº¢æ»¡<br>OSError: [Errno 28] <br>No space left on device:<br>'/tmp/data_files'| | ä»/tmp/ç›®å½•è°ƒæ•´åˆ°/data/XXX/ç›®å½•| 
 15 | Save checkpointsï¼Œ<br>æŒ‰ç…§å›ºå®šstepsè®¡ç®—perplexityï¼Œ<br>ä¿å­˜æœ€ä¼˜æ¨¡å‹| æ¯ä¸ªepochç»“æŸå<br>æ‰è®¡ç®—perplexity| å¢åŠ ä¸€ä¸ªå‚æ•° args.eval_save_stepsï¼Œ<br>é»˜è®¤100| 
 16 | Save checkpoint å¹¶è¡ŒåŒ–| checkpoint<br>è·¯å¾„å…¨å±€å”¯ä¸€ï¼Œ<br>å¦‚æœåœ¨å¤šä¸ªèŠ‚ç‚¹ï¼ˆgnodeï¼‰ä¸Šå¯åŠ¨ä»»åŠ¡ï¼Œ<br>è¾“å‡ºè·¯å¾„é‡åˆï¼Œ<br>äº’ç›¸å¹²æ‰°è¾“å‡ºç»“æœ| Save è·¯å¾„ä¸Šæ–°å¢ä¸€ä¸ªèŠ‚ç‚¹åå­—ï¼Œ<br>å¯ä»¥åŒæ—¶å¤šæœºå¯åŠ¨å¤šä¸ªä¸€æ ·çš„ä»»åŠ¡ã€‚<br>è·¯å¾„ä¾‹å­ï¼š/hpc_data/XXX/<br>actor-models/chinese_llama_plus-gnode07-13b-gnode07-20230524-0356ã€‚| chinese_llama_plus-gnode07-13b-gnode07-20230524-0356ï¼š<br>æ¨¡å‹åå­—-æ¨¡å‹å¤§å°-èŠ‚ç‚¹åå­—-æ—¶é—´ä¸²
 17 |åŠ å…¥wandb | |![Screen Shot 2023-06-05 at 5 33 49 PM](https://github.com/xubuvd/LLMs/assets/59753505/0ceac3f9-8fac-40c8-b374-47b9f166f276)| è®­ç»ƒå‚æ•°ï¼Œèµ„æºå’ŒæŒ‡æ ‡å¯è§†åŒ–<br>f"{model_name}-{JOB_ID}"
 18 |åŠ å…¥TGS,TFlops | |![W B Chart 5_25_2023, 11_35_14 AM](https://github.com/xubuvd/LLMs/assets/59753505/1ab9fd41-ee38-4b40-8be8-4e0b53078310)![W B Chart 5_25_2023, 11_35_24 AM](https://github.com/xubuvd/LLMs/assets/59753505/c1171af6-24f5-4c6c-97b8-29d02833622c) | å¡ååç‡
 19 | ç»Ÿè®¡é¢„è®­ç»ƒå’Œ<br>æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†çš„<br>æ€»tokensæ•°é‡| | | 60Wæ¡SFTæ•°æ®é›†<br>*Total tokens for pre-training: 0<br>Total tokens for sft: 51166867<br>*Total tokens: 51166867
 20 |è‡ªåŠ¨è®°å½•<br>è®­ç»ƒçš„è¶…å‚æ•°<br>Copy run_*.shåˆ°<br>è¾“å‡ºç›®å½•ä¸‹ | |copy2(script, <br>f'{output_dir}/run.sh')| æ¨¡å‹çš„è¶…å‚æ•°ä¸<br>æ¨¡å‹checkpointæ–‡ä»¶<br>ä¿å­˜åœ¨ä¸€èµ·ï¼Œ<br>ä¾¿äºåˆ†ææ¨¡å‹æ€§èƒ½ä¸<br>å‚æ•°çš„å…³ç³»
 21 | RuntimeError: Too many open files. <br>Communication with the workers is no longer possible. <br>Please increase the limit using <br>ulimit -n in the shell or <br>change the sharing strategy by <br>calling torch.multiprocessing.set_sharing_strategy('file_system')<br> at the beginning of your code | |torch.multiprocessing.<br>set_sharing_strategy<br>('file_system') |å¿«é€Ÿæ–‡ä»¶å­˜å‚¨ç³»ç»Ÿçš„è®¾ç½®å­˜åœ¨é—®é¢˜
 22 |ç¼ºå°‘å¤šæœºå¤šå¡æ”¯æŒ| | |deepspeed-chatæ²¡æœ‰å†™è¿™éƒ¨åˆ†ï¼Œå¢åŠ è¿›è¡Œä¸­
 23 |torch.cuda.OutOfMemoryError:<br>CUDA out of memory.| Chinese-LLaMA-13Bçš„æ¨¡å‹è®­ç»ƒé‡åˆ°OOMé—®é¢˜| | åœ¨epoch å¾ªç¯çš„å†…éƒ¨ï¼Œè¿›è¡Œäº† evaluation()ï¼Œ<br>evaluationè®¾ç½®äº†model.eval()æ¨¡å¼, <br>ä½†æ˜¯é€€å‡ºevaluationå†æ¬¡è¿›å…¥ epoch å¾ªç¯æ—¶ï¼Œ<br>æ²¡æœ‰è®¾ç½®model.train()æ¨¡å¼ã€‚
 24 |A100-PCIeä¸»æ¿æ¥å£ç½‘é€Ÿç“¶é¢ˆ| |<img width="1393" alt="Screen Shot 2023-05-25 at 4 33 20 PM" src="https://github.com/xubuvd/LLMs/assets/59753505/92fa0fcd-19cd-461b-94a1-0eefa951e0fb"> | è®­ç»ƒæ­£å‘è¿›è¡Œå’Œåå‘è¿›è¡Œï¼Œ<br>GPUè¾¾åˆ°å³°å€¼ï¼Œ<br>å¤šå¡ä¹‹é—´ä¿¡æ¯åŒæ­¥æ—¶ï¼Œ<br>GPUåˆ©ç”¨ç‡è·Œå€’è°·åº•ã€‚<br>NV-linkçš„æ¥å£GPUå¹³ç¨³ã€‚
 25 | Index cache<br>æ–‡ä»¶åå­—é‡åˆ | ä¸‹ä¸€ä¸ªæ–‡ä»¶ä½¿ç”¨äº†<br>å‰ä¸€ä¸ªæ–‡ä»¶çš„ç´¢å¼•<br>d_path:f_identity_qa_cn_re.json, train_dataset_size:198991, eval_dataset:1009<br>d_path:f_multiturn_cn_69k.json, train_dataset_size:69318, eval_dataset:336<br>d_path:f_ver_qa_cn_28k.json, train_dataset_size:28140, eval_dataset:166 | ç´¢å¼•ä½¿ç”¨åŸºåº§æ¨¡å‹åå­—ï¼Œ<br>è®­ç»ƒæ•°æ®æ–‡ä»¶åå­—åŒºåˆ«å¼€ |  
 26 | å•æ¡æ•°æ®ä¸è¡¥é½åˆ°<br>max_seq_len,<br>batchå†…éƒ¨æ•°æ®è¡¥é½åˆ°batchå†…æœ€å¤§é•¿åº¦ | batchå†…æ‰€æœ‰æ•°æ®è¡¥é½åˆ°max_seq_len | | æé«˜è®¡ç®—æ•ˆç‡ï¼Œå¤§å¤šæ•°é•¿åº¦ç›¸å¯¹å¾ˆçŸ­
 27 | Moss-13B<br>losså¼‚å¸¸ | ![img_v2_9723abf5-9038-4a56-97db-e9efa35fcf5g](https://github.com/xubuvd/LLMs/assets/59753505/c5a6dba6-4343-4e05-9112-2c4ad7b2694d)| <img width="685" alt="Screen Shot 2023-05-31 at 2 56 47 PM" src="https://github.com/xubuvd/LLMs/assets/59753505/73d98c57-f70b-49cd-967b-9ac736bab9cf"><img width="692" alt="Screen Shot 2023-05-31 at 2 59 33 PM" src="https://github.com/xubuvd/LLMs/assets/59753505/ff3aeaad-8a67-4bdc-af73-77dff559ceef"> | é‡æ–°è®¾ç½®lr, warmup... 
 27 | Moss-13B<br>losså¼‚å¸¸ | ![img_v2_9723abf5-9038-4a56-97db-e9efa35fcf5g](https://github.com/xubuvd/LLMs/assets/59753505/c5a6dba6-4343-4e05-9112-2c4ad7b2694d)| é‡æ–°è®¾ç½®lr, warmup... |
 28 | GPU å¡ä½ |<img width="1263" alt="Screen Shot 2023-05-31 at 7 06 50 PM" src="https://github.com/xubuvd/LLMs/assets/59753505/71d4ec0f-bc17-49e7-9401-e62777e8e5da">| | å¶å‘æ€§å¡ä½ï¼Œå¤šæœºå¤šå¡å¸¸é‡åˆ°çš„äº‹<br>è¯»æ•°æ®é˜¶æ®µï¼Œ0å·GPUå¡ä½ä¸åŠ¨.
 29 | OSError: [Errno 122] <br>Disk quota exceeded | root@master:~# quota -uvs user_name<br>Disk quotas for user user_name (uid 1006):<br>Filesystem   space   quota   limit   grace   files   quota   limit   grace<br>/dev/sda1   2862G*  2852G   2862G   6days   96582   2900k   3000k | | å¿«é€Ÿå­˜å‚¨ç³»ç»Ÿå†™æ»¡<br>åŠ ç³»ç»Ÿç›‘æ§ï¼Œå†™åˆ°80%æå‰é¢„è­¦
 30 | è¯»æ•°æ®ï¼Œæœºå™¨ä¹‹é—´<br>é€Ÿåº¦å·®åˆ«è¾ƒå¤§ | 1. gnode03æœºå™¨ï¼š<br>@master:~/$ tail -f training.log<br>3% â– 32285/1087101 [01:29<48:05, 365.57it/s]<br>2.gnode04æœºå™¨ï¼š<br>@master:~/$ tail -f training.log<br>6% â–Œ 63310/1087101 [02:53<45:11, 377.51it/s]<br>$3.gnode06æœºå™¨:<br>@master:~/$ tail -f training.log<br>19% â–ˆâ–‰ 211851/1087101 [03:36<15:01, 970.99it/s] | è¯»å–ä¸€ä¸ª108ä¸‡æ¡æ•°æ®çš„æ–‡ä»¶ï¼Œ<br>æœ‰çš„æœºå™¨èŠ‚ç‚¹è€—æ—¶50åˆ†é’Ÿï¼›<br>æœ‰çš„æœºå™¨èŠ‚ç‚¹è€—æ—¶18åˆ†é’Ÿã€‚| å¿«é€Ÿæ–‡ä»¶ç³»ç»Ÿé…ç½®å­˜åœ¨é—®é¢˜
 32 | - | - |- | æ•ˆæœä¼˜åŒ–
 33 | - | - |- | æ•ˆæœä¼˜åŒ–
 34 | - | - |- | æ•ˆæœä¼˜åŒ–
 35 | - | - |- | æ•ˆæœä¼˜åŒ–
 36 | å¯åŠ¨è®­ç»ƒæ—¶ä¸æä¾›å…·ä½“æ•°æ®æ–‡ä»¶ï¼Œ<br>åªæä¾›æ•°æ®é›†ç›®å½•ï¼Œ<br>è‡ªåŠ¨è¯»å–ç›®å½•ä¸‹çš„æ‰€æœ‰æ•°æ®æ–‡ä»¶  | æä¾›æ¯ä¸€ä¸ªè®­ç»ƒæ•°æ®æ–‡ä»¶åå­—  |æä¾›è®­ç»ƒæ•°æ®é›†ç›®å½•  | é¢„è®­ç»ƒæ•°æ®æ˜¯ç”±å¾ˆå¤šå°æ–‡ä»¶ç»„æˆçš„ï¼Œ<br>ä¸æ–¹ä¾¿åœ¨å¯åŠ¨è„šæœ¬é‡ŒåŠ å…¥è®¸å¤šæ–‡ä»¶åå­—
 37 | load_datasetä¸èƒ½è¯»å¤§æ–‡ä»¶| pyarrow.lib.ArrowCapacityError: <br>array cannot contain more than 2147483646 bytes, <br>have 2572789185 | å†…å­˜æ˜ å°„ï¼Œæµå¼è¯»å– | from datasets import load_dataset
 38 | æ•°æ®é‡è¶…å‡ºæŸä¸ªä¸´ç•Œç‚¹OOMï¼Œ<br>1Tå†…å­˜éƒ½è¢«çˆ†æ»¡ |<img width="1156" alt="Screen Shot 2023-06-10 at 12 21 25 AM" src="https://github.com/xubuvd/LLMs/assets/59753505/2585dad0-d80d-4c83-953d-d9a84e8a4fda"> | åŠ è½½æ•°æ®ä¹‹å‰ï¼Œå†…å­˜æ¶ˆè€—ï¼š<br>1-ToatlMem:1007, UsedMem:211, FreeMem:768<br>åŠ è½½æ•°æ®ä¹‹åï¼Œå†…å­˜æ¶ˆè€—ï¼š<br>2-ToatlMem:1007, UsedMem:898, FreeMem:42<br>æ­¤æ—¶ï¼Œç©ºé—²å†…å­˜42Gï¼Œå¼€å§‹è¿›å…¥ deepspeed.initializeï¼ˆï¼‰ï¼Œä½¿ç”¨çš„æ˜¯ZeRO 2ä¼˜åŒ– | åŸæ¨¡å‹è®­ç»ƒæµç¨‹æ‹†åˆ†æˆä¸¤éƒ¨åˆ†ï¼š<br>1ï¼Œ ç”Ÿæˆå†…å­˜æ˜ å°„æ–‡ä»¶ï¼ˆMemapGenï¼‰ï¼š<br>åŠ è½½åŸå§‹æ•°æ®é›†ï¼Œtokenizeråpaddingåˆ°max_seq_lenå¤§å°ï¼Œå†™å…¥å†…å­˜æ˜ å°„æ–‡ä»¶ï¼›<br>å†…å­˜æ˜ å°„æ–‡ä»¶åŒ…æ‹¬ä¸‰ä¸ªï¼Œåˆ†åˆ«æ˜¯input_idsæ–‡ä»¶ï¼Œattention_maskæ–‡ä»¶å’Œ labelsæ–‡ä»¶ï¼Œè¿˜æœ‰ä¸€ä¸ªconfig jsoné…ç½®æ–‡ä»¶ã€‚<br>2ï¼Œæ¨¡å‹è®­ç»ƒ<br>åŠ è½½configæ–‡ä»¶å’Œä¸‰ä¸ªå†…å­˜æ˜ å°„æ–‡ä»¶ï¼Œè·‘èµ·æ¥...<br>ä¼˜åŒ–ç‚¹ï¼š ç»„è£…batchæ—¶ï¼Œéšæœºè¯»å–æ•´ä¸ªæ˜ å°„æ–‡ä»¶ï¼Œé€Ÿåº¦å·¨æ…¢ï¼›MemapGenæ—¶éšæœºshuffleå¥½æ–‡ä»¶ï¼ŒåŠ è½½åæŒ‰é¡ºåºç»„è£…batchã€‚
 39 | OSError: [Errno 122] Disk quota exceeded | $ quota -uvs user_name  |  ç©ºé—´æ»¡ï¼Œæ‰€æœ‰è®­ç»ƒéƒ½ä¼šåœæ­¢   | å¢åŠ ç¡¬ç›˜å­˜å‚¨ç›‘æ§ï¼Œç©ºé—´ä½¿ç”¨85%æ—¶æå‰é¢„è­¦ï¼Œä¸»åŠ¨å‘ç°éšæ‚£ç‚¹

## iDeepSpeedChat å®è®­å¯è§†åŒ–å›¾
 ![Screen Shot 2023-06-01 at 5 56 13 PM](https://github.com/xubuvd/LLMs/assets/59753505/f22c4024-fba3-4a74-b1a5-4d1ca7107bcf)<br>
 ![Screen Shot 2023-06-05 at 5 33 49 PM](https://github.com/xubuvd/LLMs/assets/59753505/d1290a1b-cfa2-4bcd-b9e5-62a13542dbc8)<br>
 ![Screen Shot 2023-06-05 at 5 34 09 PM](https://github.com/xubuvd/LLMs/assets/59753505/ab729983-d2ee-4258-974b-ba6abbe8969c)<br>
 ![Screen Shot 2023-06-05 at 5 34 32 PM](https://github.com/xubuvd/LLMs/assets/59753505/a8ed8fee-6f2f-4259-ac34-f105a2188b60)<br>


## Open-source of LLMs 

 No. |Projects | URL  | Comments
 --------| :-----------:  |:-----------:  | :-----------:|
 1|LLaMA |  https://github.com/facebookresearch/llama | æ¨¡å‹ç»“æ„transformer block: ![LLaMA](https://user-images.githubusercontent.com/59753505/233027941-70b3b478-1137-40f1-a288-ae8858c8f7ce.jpg)
 2|OpenChatKit|https://github.com/togethercomputer/OpenChatKit | åŸºäºGPT-NeoX-20Bçš„å¾®è°ƒç‰ˆæœ¬ï¼Œ200äº¿å‚æ•°ï¼Œ48å±‚ï¼Œå•æœºå…«å¡ï¼Œæ¯å¡å…­å±‚ç½‘ç»œï¼Œæ¯ä¸€å±‚çš„æ¨¡å‹ç»“æ„ï¼š![OpenChatKit](https://user-images.githubusercontent.com/59753505/228441689-16a55551-0b0c-4c59-9c1f-0206ec9f4069.jpg)
 3|Open-Assistant | https://github.com/LAION-AI/Open-Assistant |12Bæˆ–è€…LLAMA-7Bä¸¤ä¸ªç‰ˆæœ¬ï¼ŒOpen Assistant å…¨æµç¨‹è®­ç»ƒç»†èŠ‚ï¼ˆGPT3+RLï¼‰,https://zhuanlan.zhihu.com/p/609003237
 4|ChatGLM-6B | https://github.com/THUDM/ChatGLM-6B | ChatGLM-6B æ˜¯ä¸€ä¸ªå¼€æºçš„ã€æ”¯æŒä¸­è‹±åŒè¯­çš„å¯¹è¯è¯­è¨€æ¨¡å‹ï¼ŒåŸºäº General Language Model (GLM) æ¶æ„ï¼Œå…·æœ‰ 62 äº¿å‚æ•°ã€‚å¯ä»¥ä½œä¸ºå¾ˆå¥½çš„åŸºç¡€æ¨¡å‹ï¼Œåœ¨æ­¤ä¹‹ä¸ŠåšäºŒæ¬¡ç ”å‘ï¼Œåœ¨ç‰¹å®šå‚ç›´é¢†åŸŸã€‚æ²¡æœ‰æ”¾å‡ºæºä»£ç ï¼Œåªæœ‰è®­ç»ƒå¥½çš„æ¨¡å‹ã€‚
5|GLM-130B | https://github.com/THUDM/GLM-130B/ | 1300äº¿å‚æ•°çš„ä¸­/è‹±æ–‡å¤§æ¨¡å‹ï¼Œæ²¡æœ‰æ”¾å‡ºæºä»£ç ï¼Œåªæœ‰è®­ç»ƒå¥½çš„æ¨¡å‹
6| Alpaca 7B | https://crfm.stanford.edu/2023/03/13/alpaca.html |  A Strong Open-Source Instruction-Following Modelï¼Œa model fine-tuned from the LLaMA 7B model on 52K instruction-following demonstrations. 
7| Claude | ç”¨æˆ·å¯ä»¥é€šè¿‡é‚®ç®±ç­‰ä¿¡æ¯æ³¨å†Œç”³è¯·è¯•ç”¨, äº§å“åœ°å€ï¼šhttps://www.anthropic.com/product, ç”³è¯·åœ°å€ï¼šhttps://www.anthropic.com/earlyaccess, APIè¯´æ˜: https://console.anthropic.com/docs/api |ä¸¤ä¸ªç‰ˆæœ¬çš„ Claudeï¼šClaude å’Œ Claude Instantã€‚ Claude æ˜¯æœ€å…ˆè¿›çš„é«˜æ€§èƒ½æ¨¡å‹ï¼Œè€Œ Claude Instant æ˜¯æ›´è½»ã€æ›´ä¾¿å®œã€æ›´å¿«çš„é€‰æ‹©ã€‚
8|LLama/ChatLLama|https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/chatllama | ä¸­æ–‡æ”¯æŒä¸å¥½ï¼Œæœ‰å…¨å¥—çš„SFTï¼ŒRLHFè®­ç»ƒè¿‡ç¨‹
9|chatglm-6B_finetuning | https://github.com/ssbuild/chatglm_finetuning | 1,chatGLM-6Bçš„å¾®è°ƒç‰ˆæœ¬ï¼Œæ­£åœ¨è¡¥å……RLHFä»£ç ï¼Œé™†ç»­æ”¾å‡ºæ¥ï¼›28å±‚ç½‘ç»œï¼Œæ¯ä¸€å±‚çš„æ¨¡å‹ç»“æ„ï¼š![chatglm](https://user-images.githubusercontent.com/59753505/228441877-63aae805-b862-4c42-839e-c60ef9e2d135.jpg);<br><br>2ï¼Œä¸¤ç§å¾®è°ƒæ–¹å¼ï¼šLoRAå¾®è°ƒå’ŒSFTå¾®è°ƒï¼Œ28å±‚ç½‘ç»œï¼ŒæŒ‡ä»¤æ•°æ®5Kï¼Œå•æœº8å¡ï¼ŒA100ï¼Œ80Gæ˜¾å­˜ï¼Œbatch size 8, epoch 1æˆ–2ï¼ˆæœ‰ç”Ÿæˆé‡å¤é—®é¢˜ï¼‰ï¼Œå¤§çº¦20åˆ†é’Ÿå†…å®Œæˆï¼›<br>3, å€Ÿé‰´ Colossal-AI/Open-Assistantçš„å¼ºåŒ–å­¦ä¹ ä»£ç ï¼ˆPPOï¼ŒPPO-ptxç®—æ³•ï¼‰ï¼ŒColossal-AIå¯ä»¥è¿ç§»è¿‡æ¥ï¼Œè¢«å®è·µè¿‡ã€‚<br>4ï¼ŒReward modelï¼Œå¯é€‰è¾ƒå¤šï¼Œç›´æ¥åŸºäºGLM-6Bæ¨¡å‹å¾®è°ƒä¸€ä¸ªReward modelã€‚<br>éš¾ç‚¹å°±æ˜¯è®­ç»ƒæ•°æ®ï¼›GPT3.5ä½¿ç”¨äº†33Kçš„äººå·¥æ ‡æ³¨æ•°æ®è®­ç»ƒ Reword modelã€‚<br>æ¯ä¸ªé—®é¢˜ï¼Œé…ç½®å››ä¸ªç­”æ¡ˆABCDï¼Œäººå·¥ä»å¥½åˆ°å·®æ’åºæ¯”å¦‚B>A>D>Cï¼Œæ’åºåçš„æ•°æ®å¾®è°ƒReward modelã€‚<br>å•æœº8å¡ï¼ŒA100ï¼Œ 80Gï¼Œtrain_batch_size=4, max_seq_lenè®¾ç½®æˆ512ï¼Œæ‰å¯ä»¥è·‘50Kçº§åˆ«çš„å¾®è°ƒæ•°æ®é›†ï¼Œè¿™ä»½ä»£ç æ„Ÿè§‰æœ‰ç‚¹ç–‘é—®ï¼Œéœ€è¦ä¼˜åŒ–çš„åœ°æ–¹æŒºå¤šçš„
10|ChatGLM-Tuning| https://github.com/mymusise/ChatGLM-Tuning| ChatGLM-6Bçš„åˆä¸€ä¸ªå¾®è°ƒç‰ˆæœ¬
11|ä¸­æ–‡è¯­è¨€æ¨¡å‹éª†é©¼ (Luotuo)|https://github.com/LC1332/Chinese-alpaca-lora |åŸºäº LLaMAã€Stanford Alpacaã€Alpaca LoRAã€Japanese-Alpaca-LoRA ç­‰å®Œæˆï¼Œå•å¡å°±èƒ½å®Œæˆè®­ç»ƒéƒ¨ç½²
12|Alpaca-COTæ•°æ®é›† | https://github.com/PhoebusSi/Alpaca-CoT | æ€ç»´é“¾ï¼ˆCoTï¼‰æ•°æ®é›†ï¼Œå¢å¼ºå¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›
13|Bloom | https://huggingface.co/bigscience/bloom | è®­ç»ƒå’Œä»£ç æ¯”è¾ƒå…¨
14|ä¸­æ–‡LLaMA&Alpacaå¤§è¯­è¨€æ¨¡å‹ | https://github.com/ymcui/Chinese-LLaMA-Alpaca | åœ¨åŸç‰ˆLLaMAï¼ˆ7Bå’Œ13Bï¼‰çš„åŸºç¡€ä¸Šæ‰©å……äº†ä¸­æ–‡è¯è¡¨å¹¶ä½¿ç”¨äº†ä¸­æ–‡æ•°æ®è¿›è¡ŒäºŒæ¬¡é¢„è®­ç»ƒï¼Œè¿›ä¸€æ­¥æå‡äº†ä¸­æ–‡åŸºç¡€è¯­ä¹‰ç†è§£èƒ½åŠ›ã€‚åŒæ—¶ï¼Œåœ¨ä¸­æ–‡LLaMAçš„åŸºç¡€ä¸Šï¼Œæœ¬é¡¹ç›®ä½¿ç”¨äº†ä¸­æ–‡æŒ‡ä»¤æ•°æ®è¿›è¡ŒæŒ‡ä»¤ç²¾è°ƒï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹å¯¹æŒ‡ä»¤çš„ç†è§£å’Œæ‰§è¡Œèƒ½åŠ›ã€‚
15 |Colossal-AI/ColossalChat | https://github.com/hpcaitech/ColossalAI | è®­ç»ƒå’Œä»£ç æ¯”è¾ƒå…¨ï¼ŒåŒ…æ‹¬ RLHF è®­ç»ƒä»£ç ï¼›ä»¥ LLaMA ä¸ºåŸºç¡€é¢„è®­ç»ƒæ¨¡å‹ï¼›å¼€æºäº†7Bå’Œ13Bä¸¤ç§æ¨¡å‹ï¼›
16 | Cerebras-GPTä¸ƒä¸ªç‰ˆæœ¬ | å®˜ç½‘åœ°å€ï¼šhttps://www.cerebras.net/blog/cerebras-gpt-a-family-of-open-compute-efficient-large-language-models<br>GPTåœ°å€:https://www.cerebras.net/cerebras-gpt<br>Hugging Faceåœ°å€:https://huggingface.co/cerebras | ä¸ƒä¸ªå‚æ•°ç‰ˆæœ¬ï¼š1.16äº¿ã€2.56äº¿ã€5.9äº¿ã€13äº¿ã€27äº¿ã€67äº¿å’Œ130äº¿å‚æ•°, åŸºäºGPTçš„ç”Ÿæˆäººå·¥æ™ºèƒ½å¤§å‹è¯­è¨€æ¨¡å‹
17 | BloombergGPT<br>(é‡‘èé¢†åŸŸ) | https://arxiv.org/abs/2303.17564 | BloombergGPTçš„è®­ç»ƒæ•°æ®åº“åä¸ºFINPILEï¼Œæ„å»ºè¿„ä»Šä¸ºæ­¢æœ€å¤§çš„ç‰¹å®šé¢†åŸŸæ•°æ®é›†, ç”±ä¸€ç³»åˆ—è‹±æ–‡é‡‘èä¿¡æ¯ç»„æˆï¼ŒåŒ…æ‹¬æ–°é—»ã€æ–‡ä»¶ã€æ–°é—»ç¨¿ã€ç½‘ç»œçˆ¬å–çš„é‡‘èæ–‡ä»¶ä»¥åŠæå–åˆ°çš„ç¤¾äº¤åª’ä½“æ¶ˆæ¯ã€‚è®­ç»ƒä¸“é—¨ç”¨äºé‡‘èé¢†åŸŸçš„LLMï¼Œæ‹¥æœ‰500äº¿å‚æ•°çš„è¯­è¨€æ¨¡å‹ã€‚
18 | dolly-v1-6b | https://github.com/databrickslabs/dolly | 1, fine-tuned on a ~52K instruction (Self-Instructä» ChatGPTè‡ªåŠ¨è·å–)ï¼›<br>2ï¼Œdeepspeed ZeRo 3åŠ é€Ÿè®­ç»ƒ;<br>3.å¯å€Ÿé‰´çš„ï¼šdeepspeed ZeRo 3åŠ é€Ÿè®­ç»ƒéƒ¨åˆ†ï¼›
19 | ChatDoctor | https://github.com/Kent0n-Li/ChatDoctor | åŒ»ç–—é¢†åŸŸå¯¹è¯æ¨¡å‹ï¼ŒåŸºäºLLaMA-7Bå¾®è°ƒçš„å¤§æ¨¡å‹ï¼Œç»è¿‡å››è½®å¾®è°ƒï¼š<br>ç¬¬ä¸€è½®å¾®è°ƒï¼šç¾Šé©¼çš„52K instruction-following æ•°æ®<br>;ç¬¬äºŒè½®å¾®è°ƒï¼šæ‚£è€…å’ŒåŒ»ç”Ÿä¹‹é—´çš„5Kå¯¹è¯æ•°æ®é›†ï¼ˆChatGPT GenMedGPT-5kå’Œç–¾ç—…æ•°æ®åº“ç”Ÿæˆï¼‰ï¼›<br>ç¬¬ä¸‰è½®å¾®è°ƒï¼šæ‚£è€…å’ŒåŒ»ç”Ÿä¹‹é—´çš„çœŸå®å¯¹è¯ï¼ˆHealthCareMagic-200kï¼‰ï¼›<br>ç¬¬å››è½®å¾®è°ƒï¼šæ‚£è€…å’ŒåŒ»ç”Ÿä¹‹é—´çš„çœŸå®å¯¹è¯ï¼ˆicliniq-26kï¼‰.
20 | å¼€æºä¸­æ–‡å¯¹è¯å¤§æ¨¡å‹BELLE | https://github.com/LianjiaTech/BELLE | BELLE-7Bï¼ˆåŸºäº BLOOMZ-7B1-mt å¾®è°ƒï¼‰<br>BELLE-13Bçš„æ„Ÿè§‰è¿˜è¡Œ
21 |  InstructGLM | https://github.com/yanqiangmiffy/InstructGLM | åŸºäºChatGLM-6B+LoRAåœ¨æŒ‡ä»¤æ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒï¼›æˆªæ­¢4æœˆ4å·ä¸‹åˆï¼ŒInstructGLMå­˜åœ¨ä»¥ä¸‹ç¼ºç‚¹ï¼šå¤šå¡ä¸æ”¯æŒï¼ŒåŸä½œè€…åœ¨å›ç­”issuesæ—¶ä¹Ÿç¡®è®¤äº†ï¼›ç¤¾åŒºä¸æ´»è·ƒï¼Œä¸¤å‘¨ä¸æ›´æ–°ä»£ç ï¼Œå‘åé¦ˆçš„å¤ªå°‘ï¼ˆæ‰11æ¡ï¼‰ï¼Œdeepspeedæ²¡æœ‰ï¼›è¿™æ˜¯æˆ‘ç”¨ä¸‰å—å¡è·‘ï¼Œå¡è´Ÿè½½ä¸å‡è¡¡ï¼š![image](https://user-images.githubusercontent.com/59753505/229748872-df8f3909-f8e5-454c-8378-56766f8aa1a2.png)
22 | Cerebras-GPT  | https://huggingface.co/cerebras/Cerebras-GPT-13B | å‚æ•°é‡çº§130äº¿ï¼Œå¤§å°æ¯”è‚©æœ€è¿‘Metaå¼€æ”¾çš„LLaMA-13Bï¼Œæ•°æ®é›†ã€æ¨¡å‹æƒé‡å’Œè®¡ç®—ä¼˜åŒ–è®­ç»ƒï¼Œå…¨éƒ¨å¼€æºã€‚å¯å•†ç”¨ï¼
23 | Baize<br>(åŠ åˆ©ç¦å°¼äºšå¤§å­¦, åŸºäº LLaMA çš„å¾®è°ƒ)|https://github.com/project-baize/baize-chatbot | æ•°æ®é›†ç”Ÿæˆ: è®© ChatGPT ä¸è‡ªå·±è¿›è¡Œå¯¹è¯ï¼Œæ¨¡æ‹Ÿç”¨æˆ·å’ŒAIæœºå™¨äººçš„å›å¤ã€ã€‚è¿™ä¸ªç”Ÿæˆçš„è¯­æ–™æ•°æ®é›†æ˜¯åœ¨å¤šè½®å¯¹è¯çš„èƒŒæ™¯ä¸‹è®­ç»ƒå’Œè¯„ä¼°èŠå¤©æ¨¡å‹çš„å®è´µèµ„æºã€‚æ­¤å¤–ï¼Œé€šè¿‡æŒ‡å®šç§å­æ•°æ®é›†ï¼Œå¯ä»¥ä»ç‰¹å®šé¢†åŸŸè¿›è¡Œé‡‡æ ·ï¼Œå¹¶å¾®è°ƒèŠå¤©æ¨¡å‹ä»¥ä¸“é—¨é’ˆå¯¹ç‰¹å®šé¢†åŸŸï¼Œä¾‹å¦‚åŒ»ç–—ä¿å¥æˆ–é‡‘èã€‚<br>Parameter-efficient tuningï¼Œ è¾“å…¥åºåˆ—çš„æœ€å¤§é•¿åº¦è®¾ç½®ä¸º512ï¼ŒLoRAä¸­çš„ç§©kè®¾ç½®ä¸º8ï¼Œä½¿ç”¨8ä½æ•´æ•°æ ¼å¼ (int8) ï¼ŒAdam ä¼˜åŒ–å™¨ã€æ›´æ–°LoRA å‚æ•°ï¼Œbatch sizeä¸º64ï¼Œlearning rateä¸º2e-4ã€1e-4å’Œ 5e-5ï¼Œå¯è®­ç»ƒçš„LoRAå‚æ•°åœ¨ NVIDIA A100-80GB GPU ä¸Šå¾®è°ƒäº†1ä¸ª epochã€‚
24 | Open-Llama |https://github.com/s-JoL/Open-Llama | Open-Llamaæ˜¯ä¸€ä¸ªå¼€æºé¡¹ç›®ï¼Œæä¾›äº†ä¸€æ•´å¥—ç”¨äºæ„å»ºå¤§å‹è¯­è¨€æ¨¡å‹çš„è®­ç»ƒæµç¨‹ï¼Œä»æ•°æ®é›†å‡†å¤‡åˆ°åˆ†è¯ã€é¢„è®­ç»ƒã€æŒ‡ä»¤è°ƒä¼˜ï¼Œä»¥åŠå¼ºåŒ–å­¦ä¹ æŠ€æœ¯ RLHFã€‚é‡‡ç”¨FastChaté¡¹ç›®ç›¸åŒæ–¹æ³•æµ‹è¯„Open-Llamaçš„æ•ˆæœå’ŒGPT3.5çš„æ•ˆæœå¯¹æ¯”ï¼Œç»è¿‡æµ‹è¯•åœ¨ä¸­æ–‡é—®é¢˜ä¸Šå¯ä»¥è¾¾åˆ°GPT3.5 84%çš„æ°´å¹³ã€‚
25  | DeepSpeed-Chat | https://github.com/microsoft/DeepSpeed/tree/master/blogs/deepspeed-chat<br>https://github.com/microsoft/DeepSpeedExamples | å¾®è°ƒæ¡†æ¶ï¼šåŒ…æ‹¬æŒ‡ä»¤å¾®è°ƒï¼ˆSFTï¼‰ï¼ŒReward model å’Œå¼ºåŒ–å­¦ä¹ å¯¹é½æ„å›¾ï¼ˆRLHFï¼‰
26 | fairseq | https://github.com/facebookresearch/fairseq | FaceBookå¼€æºçš„å¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒæ¡†æ¶
27 | metaseq | https://github.com/facebookresearch/metaseq | FaceBookå¼€æºçš„å¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒæ¨¡å‹æ¡†æ¶ï¼ŒåŸºäºfairseqçš„æ–°ç‰ˆæœ¬
28 | MiniGPT-4 | https://github.com/Vision-CAIR/MiniGPT-4 | å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ŒåŸºäº BLIP-2 å’Œ Vicunaï¼ˆLLaMA-7BåŸºåº§ï¼‰, é˜¿åœæœæ‹‰å›½ç‹ç§‘æŠ€å¤§å­¦
29 | moss<br>(å¤æ—¦å¤§å­¦) | https://github.com/OpenLMLab/MOSS<br>https://huggingface.co/models?other=moss | moss-13Bå¼€æºäº†ï¼Œé‡è¦è´¡çŒ®æ˜¯æä¾›äº†ä¸€ä¸ªçº¯åŸºåº§
30 | çº¢ç¡è¡£(RedPajama)å¼€æºè®¡åˆ’ | https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T<br>é¢„å¤„ç†ä»“åº“:https://github.com/togethercomputer/RedPajama-Data | çº¢ç¡è¡£å¼€æºè®¡åˆ’æ€»å…±åŒ…æ‹¬ä¸‰éƒ¨åˆ†ï¼š<br>1. é«˜è´¨é‡ã€å¤§è§„æ¨¡ã€é«˜è¦†ç›–åº¦çš„é¢„è®­ç»ƒæ•°æ®é›†ï¼›<br>2. åœ¨é¢„è®­ç»ƒæ•°æ®é›†ä¸Šè®­ç»ƒå‡ºçš„åŸºç¡€æ¨¡å‹ï¼›<br>3. æŒ‡ä»¤è°ƒä¼˜æ•°æ®é›†å’Œæ¨¡å‹ï¼Œæ¯”åŸºæœ¬æ¨¡å‹æ›´å®‰å…¨ã€å¯é ã€‚<br>Ontocord.AIï¼Œè‹é»ä¸–è”é‚¦ç†å·¥å­¦é™¢DS3Labï¼Œæ–¯å¦ç¦CRFMï¼Œæ–¯å¦ç¦Hazy Research å’Œè’™ç‰¹åˆ©å°”å­¦ä¹ ç®—æ³•ç ”ç©¶æ‰€çš„å¼€æºè®¡åˆ’ï¼Œæ—¨åœ¨ç”Ÿæˆå¯å¤ç°ã€å®Œå…¨å¼€æ”¾ã€æœ€å…ˆè¿›çš„è¯­è¨€æ¨¡å‹ï¼Œå³ä»é›¶ä¸€ç›´å¼€æºåˆ°ChatGPTï¼ã€‚
31 | Panda<br>ä¸­æ–‡å¼€æºå¤§è¯­è¨€æ¨¡å‹ |  https://github.com/dandelionsllm/pandallm |åŸºäºLlama-7Bã€-13Bã€-33Bå’Œ-65Bè¿›è¡Œäº†ä¸­æ–‡é¢†åŸŸçš„æŒç»­é¢„è®­ç»ƒï¼Œåœ¨ä¸­æ–‡åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè¿œè¶…åŒç­‰ç±»å‹çš„ä¸­æ–‡è¯­è¨€æ¨¡å‹ï¼ŒPandaçš„æ¨¡å‹å’Œè®­ç»ƒæ‰€ç”¨ä¸­æ–‡æ•°æ®é›†å°†ä»¥å¼€æºå½¢å¼å‘å¸ƒï¼Œä»»ä½•äººéƒ½å¯ä»¥å…è´¹ä½¿ç”¨å’Œå‚ä¸å¼€å‘ã€‚
32 | BELLE<br>ï¼ˆLLaMAï¼Œé“¾å®¶ï¼‰ | https://github.com/LianjiaTech/BELLE | BELLE-LLaMA-EXT-13Bï¼Œåœ¨LLaMA-13Bçš„åŸºç¡€ä¸Šæ‰©å±•ä¸­æ–‡è¯è¡¨ï¼Œå¹¶åœ¨400ä¸‡é«˜è´¨é‡çš„å¯¹è¯æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒã€‚
33 | Linly-Chinese-LLaMA   | https://github.com/CVI-SZU/Linly | LLaMA-7B/13BåŸºç¡€ä¸Šï¼Œä¸­æ–‡äºŒæ¬¡é¢„è®­ç»ƒï¼Œä¸Šä¸‹æ–‡é•¿åº¦2048
34 | CAMEL        | https://github.com/camel-ai/camel  | https://www.camel-ai.org/chat
35 | Ziya-LLaMA-13B-v1 | https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-v1 | å§œå­ç‰™é€šç”¨å¤§æ¨¡å‹V1æ˜¯åŸºäºLLaMaçš„130äº¿å‚æ•°çš„å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹
36 | æ‚Ÿé“Â·å¤©é¹°ï¼ˆAquilaï¼‰ | https://github.com/FlagAI-Open/FlagAI/tree/master/examples/Aquila/Aquila-chat |

## ColossalAI çš„æ€§èƒ½æµ‹è¯•
1ï¼Œ ZeRO 2çš„æ€§èƒ½ï¼Œtflops çº¦ä¸º251<br>
![Screen Shot 2023-04-21 at 10 32 14 AM](https://user-images.githubusercontent.com/59753505/233526814-3331b468-37d0-44dc-8484-d78da549466a.png)<br>
2, ZeRO 2å’Œ3çš„æ€§èƒ½å¯¹æ¯”<br>

Model    |   ZeRO        | GPUæ•°é‡	       | Bs	          | Seq len	    | Gpu mem	    | Gpu Usage	  | Iter	       |  Tflops	 |   TGS<br>(tokens per gpu per second)
--------| :-----------:  |:-----------:  | :-----------:|:-----------:|:-----------:|:-----------:|:-----------:|:-----------:|:-----------:|  
LLaMA-7B | zero2	        |  2            | 50	          | 2048	       |  90%	       |    60%	     |   25s	      |      250	 |   4096
LLaMA-7B |zero3	         |  2            | 76	          | 2048	       |  97%	       |    80%	     |   30s	      |      300	 |   5188

3, é»„è‰²æ›²çº¿æ˜¯ZeRO3ï¼Œç»¿è‰²æ›²çº¿æ˜¯ZeRO2<br>
![img_v2_ef608a22-cae9-41a1-b725-0946e695e92g](https://user-images.githubusercontent.com/59753505/233527058-cb9a3bc8-23f3-456f-8bd8-6a8a773ae2f6.png)

## åŒ—äº¬é‚®ç”µå¤§å­¦ ç‹å°æ·æ•™æˆ ChatGPT è®²åº§åˆ†äº«

https://www.bilibili.com/video/BV1G24y187yx/?buvid=ZB476BB0B8710E3C4F548C7C2778AA1427C6&is_story_h5=false&mid=AdBmq4Rn7y73B2EmgVj16A%3D%3D&p=1&plat_id=114&share_from=ugc&share_medium=iphone&share_plat=ios&share_session_id=5BB03E0F-3FED-48AF-A5FE-7F3E52513D99&share_source=WEIXIN&share_tag=s_i&timestamp=1677718075&unique_k=lk400UP&up_id=354740423<br>

## è‡´è°¢
 
